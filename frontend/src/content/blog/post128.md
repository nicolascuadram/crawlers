---
title: "Implicit or Explicit: Gaze-Based Audio Commentaries for Ancient Painting Exhibitions in VR"
description: "International Journal of Human–Computer Interaction"
url: "https://www.tandfonline.com/doi/full/10.1080/10447318.2025.2491792"
type: "paper"
pubDate: "Article |Published online: 13 Jun 2025"
created_at: "2025-06-13 13:34:13.297481"
log_id: 16
sourcename: Taylor & Francis
author: "Xin Ge,Xiaojiao Chen,Xiaoteng Tang&Xiaosong Wang"
heroImage: /blog-placeholder-3.jpg
linkDownload: "https://www.tandfonline.com/doi/full/10.1080/10447318.2025.2491792"
---

Eye-tracking technology presents the potential to enable more personalized audio commentaries. However, previous research has focused on the technical aspects of gaze-based audio commentary systems. In this study, we proposed three methods of gaze-based audio commentaries based on the eye-controlled interaction paradigms and developed three prototypes: implicit, explicit, and implicit & explicit. Results from a controlled study (N = 45) in virtual museums exhibiting ancient paintings indicated that the explicit method obtained better performance in terms of commentary experience, commentary quality, and intrinsic motivation, which were largely long-term. All three methods of gaze-based audio commentaries somewhat hindered users’ acquisition of audio information, but they facilitated the acquisition of visual information. Among them, the implicit method supported users in learning the details of visual information, while the explicit method aided in learning the position and dimension of visual information. Nevertheless, they lacked long-term value for users’ retention of the information.
